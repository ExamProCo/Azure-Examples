{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad8502-2fbe-44bc-97be-da0fa7b15f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resources\n",
    "\n",
    "https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/textanalytics/azure-ai-textanalytics/samples/sample_abstract_summary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c858ae82-ee31-4eb3-be79-41e6406ae31b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-textanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb1c75-3626-4c17-9868-19334fab9e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Congitive Key and Endpoint Configuration\n",
    "my_key      = '###'\n",
    "my_endpoint = '###'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81de2d-33ee-43ed-b8fc-a20afe5f777a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2255bfa-0655-475f-bcee-b6eff4dbdd50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = TextAnalyticsClient(\n",
    "    endpoint=my_endpoint,\n",
    "    credential=AzureKeyCredential(my_key),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6a127a-0a80-43b5-af26-a0c2f47afde8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "document = [\n",
    "    \"At Microsoft, we have been on a quest to advance AI beyond existing techniques, by taking a more holistic, \"\n",
    "    \"human-centric approach to learning and understanding. As Chief Technology Officer of Azure AI Cognitive \"\n",
    "    \"Services, I have been working with a team of amazing scientists and engineers to turn this quest into a \"\n",
    "    \"reality. In my role, I enjoy a unique perspective in viewing the relationship among three attributes of \"\n",
    "    \"human cognition: monolingual text (X), audio or visual sensory signals, (Y) and multilingual (Z). At the \"\n",
    "    \"intersection of all three, there's magic-what we call XYZ-code as illustrated in Figure 1-a joint \"\n",
    "    \"representation to create more powerful AI that can speak, hear, see, and understand humans better. \"\n",
    "    \"We believe XYZ-code will enable us to fulfill our long-term vision: cross-domain transfer learning, \"\n",
    "    \"spanning modalities and languages. The goal is to have pretrained models that can jointly learn \"\n",
    "    \"representations to support a broad range of downstream AI tasks, much in the way humans do today. \"\n",
    "    \"Over the past five years, we have achieved human performance on benchmarks in conversational speech \"\n",
    "    \"recognition, machine translation, conversational question answering, machine reading comprehension, \"\n",
    "    \"and image captioning. These five breakthroughs provided us with strong signals toward our more ambitious \"\n",
    "    \"aspiration to produce a leap in AI capabilities, achieving multisensory and multilingual learning that \"\n",
    "    \"is closer in line with how humans learn and understand. I believe the joint XYZ-code is a foundational \"\n",
    "    \"component of this aspiration, if grounded with external knowledge sources in the downstream AI tasks.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffdaea-e14f-40bf-85b7-4619083305a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poller = client.begin_abstract_summary(documents=document)\n",
    "results = poller.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5cee8a-3c82-4dc5-99ad-28ffbb4c4eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    if result.kind == \"AbstractiveSummarization\":\n",
    "        print(\"Summaries abstracted:\")\n",
    "        [print(f\"{summary.text}\\n\") for summary in result.summaries]\n",
    "    elif result.is_error is True:\n",
    "        print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "            result.error.code, result.error.message\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b1871d-13e2-435a-9f54-ec465dbb3f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for result in results:        \n",
    "    if result.kind == \"ExtractiveSummarization\":\n",
    "        print(\"Summary extracted: \\n{}\".format(\n",
    "            \" \".join([sentence.text for sentence in result.sentences]))\n",
    "        )\n",
    "    elif result.is_error is True:\n",
    "        print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "            result.error.code, result.error.message\n",
    "        ))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6e4fd-c49a-4acc-aa8a-284b74aae944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
